import pandas as pd
import os
import sys
import cerberus
import itertools

from utils import *
from sm_utils import *
from humanized_utils import *

configfile: 'config.yml'
config_tsv = 'config.tsv'
p_meta_tsv = 'pseudochromosome_metadata.tsv'
meta_tsv = 'mouse_metadata.tsv'
geno_tsv = 'genotype_metadata.tsv'
auto_dedupe = True

df, p_df = parse_config_file(config_tsv,
                       meta_tsv,
                       p_meta_tsv,
                       geno_tsv,
                       auto_dedupe=auto_dedupe)
end_modes = ['tss', 'tes']
strands = ['fwd', 'rev']

include: 'download.smk'
include: 'samtools.smk'
include: 'refs.smk'
include: 'talon.smk'
include: 'lapa.smk'
include: 'mapping.smk'
include: 'tc.smk'
include: 'cerberus.smk'
include: 'deeptools.smk'
include: 'igvtools.smk'
include: 'pseudochrom.smk'
# include: 'swan.smk'

wildcard_constraints:
    genotype='|'.join([re.escape(x) for x in df.genotype.unique().tolist()]),
    sex='|'.join([re.escape(x) for x in df.sex.unique().tolist()]),
    age='|'.join([re.escape(x) for x in df.age.unique().tolist()]),
    tissue='|'.join([re.escape(x) for x in df.tissue.unique().tolist()]),
    biorep_num='|'.join([re.escape(x) for x in df.biorep_num.unique().tolist()]),
    flowcell='|'.join([re.escape(x) for x in df.flowcell.unique().tolist()]),

ruleorder:
    # cerberus_agg_ics_first > cerberus_agg_ics_seq
    # cerb_agg_ics_first > cerb_agg_ics_seq > cerb_agg_ends_first > cerb_agg_ends_seq

# max_cerb = df.loc[df.cerberus_run.astype(int)==df.cerberus_run.astype(int).max(axis=0)]
# max_cerb = df.loc[df.cerberus_run.astype(int)==3]

# temp
g_temp = 'hTREM2KI-WT'
s_temp='M'
a_temp='8_months'
tissue_temp = 'HC'
df = df.loc[(df.genotype==g_temp)&\
            (df.sex==s_temp)&\
            (df.age==a_temp)&\
            (df.tissue==tissue_temp)]

rule all:
    input:
        config['ref']['cerberus']['ics'],
        expand(config['ref']['cerberus']['ends'],
               end_mode=end_modes),
        expand(expand(config['merge']['bw'],
                zip,
                study=df.study.tolist(),
                genotype=df.genotype.tolist(),
                sex=df.sex.tolist(),
                age=df.age.tolist(),
                tissue=df.tissue.tolist(),
                biorep_num=df.biorep_num.tolist(),
                allow_missing=True),
                strand=['fwd', 'rev']),
        expand(config['cerberus']['ics'],
               zip,
               study=df.study.tolist(),
               genotype=df.genotype.tolist(),
               sex=df.sex.tolist(),
               age=df.age.tolist(),
               tissue=df.tissue.tolist()),
        expand(expand(config['cerberus']['ends'],
            zip,
            study=df.study.tolist(),
            genotype=df.genotype.tolist(),
            sex=df.sex.tolist(),
            age=df.age.tolist(),
            tissue=df.tissue.tolist(),
            allow_missing=True),
            end_mode=end_modes),
        expand(config['lapa']['filt']['filt_ab'],
              zip,
              study=df.study.tolist(),
              genotype=df.genotype.tolist(),
              sex=df.sex.tolist(),
              age=df.age.tolist(),
              tissue=df.tissue.tolist()),
        expand(config['talon']['ab'],
            zip,
            study=df.study.tolist(),
            genotype=df.genotype.tolist(),
            sex=df.sex.tolist(),
            age=df.age.tolist(),
            tissue=df.tissue.tolist())

################################################################################
#################################### Mapping ###################################
################################################################################
use rule map as map_reads with:
    input:
        fastq = lambda wc: get_df_col(wc, df, 'fname'),
        ref_fa = rules.mkref_genome.output.out,
        # ref_fa = config['ref']['fa'],
        sjs = config['ref']['sjs']
    output:
        sam = temporary(config['map']['sam']),
        log = config['map']['log']

use rule alignment_stats as map_stats with:
    input:
        alignment = config['map']['sam']
    output:
        stats = config['map']['stats']

use rule rev_alignment as map_rev with:
    input:
        sam = config['map']['sam']
    output:
        sam_rev = temporary(config['map']['sam_rev'])


################################################################################
###################### TranscriptClean ##########################################
################################################################################
use rule tc as tc_sam with:
    input:
        sam = config['map']['sam_rev'],
        fa = rules.map_reads.input.ref_fa
    params:
        min_intron_size = config['tc']['min_intron_size'],
        opref = config['tc']['sam'].rsplit('_clean.sam', maxsplit=1)[0]
    output:
        sam = temporary(config['tc']['sam']),
        fa = temporary(config['tc']['fa']),
        sam_clean_log = temporary(config['tc']['log']),
        sam_clean_te_log = temporary(config['tc']['te_log'])

use rule alignment_stats as tc_stats with:
    input:
        alignment = config['tc']['sam']
    output:
        stats = config['tc']['stats']

################################################################################
############################## TALON label #####################################
################################################################################
use rule talon_label as talon_label_reads with:
    input:
        fa = rules.map_reads.input.ref_fa,
        sam = config['tc']['sam']
    params:
        frac_a_range = config['talon_label']['frac_a_range'],
        opref = config['talon_label']['sam'].rsplit('_labeled.sam', maxsplit=1)[0]
    output:
        sam = temporary(config['talon_label']['sam'])

use rule sam_to_bam as bam_from_sam with:
    input:
        sam = config['talon_label']['sam']
    output:
        bam = temporary(config['talon_label']['bam'])

use rule sort_bam as bam_sort with:
    input:
        bam = config['talon_label']['bam']
    output:
        bam = temporary(config['talon_label']['sort_bam'])

use rule index_bam as bam_ind with:
    input:
        bam = config['talon_label']['sort_bam']
    output:
        ind = temporary(config['talon_label']['ind_bam'])

################################################################################
################# Merge data from separate flowcells ###########################
##################### Sort, index, make bigwigs ################################
################################################################################
use rule merge_alignment as talon_label_merge with:
    input:
        files = lambda wc:get_cfg_entries(wc, p_df, config['talon_label']['sort_bam'])
    output:
        bam = temporary(config['merge']['bam'])

use rule sort_bam as bam_sort_merge with:
    input:
        bam = config['merge']['bam']
    output:
        bam = protected(config['merge']['sort_bam'])


use rule index_bam as bam_ind_merge with:
    input:
        bam = config['merge']['sort_bam']
    output:
        ind = protected(config['merge']['ind_bam'])


use rule bam_to_bw as bw with:
    input:
        bam = config['merge']['sort_bam'],
        bai = config['merge']['ind_bam']
    output:
        bw = protected(config['merge']['bw'])


################################################################################
################################## TALON #######################################
################################################################################
rule talon_config:
    input:
        bams = lambda wc:get_cfg_entries(wc, p_df, config['merge']['sort_bam']),
        bam_inds = lambda wc:get_cfg_entries(wc, p_df, config['merge']['ind_bam']),
    resources:
        threads = 1,
        mem_gb = 4
    output:
        cfg = protected(config['talon']['config'])
    run:
        temp = get_cfg_entries(wildcards, p_df, config['merge']['sort_bam'], return_df=True)
        temp = temp[['dataset', 'sample', 'platform', 'file']]
        temp.to_csv(output.cfg, index=False, header=None, sep=',')

# use rule talon_init as talon_init_db with:
#     input:
#         gtf = config['ref']['gtf']
#     output:
#         db = config['ref']['talon']['db']
#     params:
#         opref = config['ref']['talon']['db'].rsplit('.db', maxsplit=1)[0],
#         genome_ver = config['ref']['fa_ver'],
#         annot_ver = config['ref']['gtf_ver'],
#         min_transcript_len = config['talon']['min_transcript_len'],
#         max_5_dist = config['talon']['max_5_dist'],
#         max_3_dist = config['talon']['max_3_dist']

use rule talon as talon_run with:
    input:
        db = rules.talon_init_db.output.db,
        cfg = config['talon']['config']
    params:
        genome_ver = config['ref']['fa_ver'],
        opref = config['talon']['db'].rsplit('_talon.db', maxsplit=1)[0]
    output:
        db = protected(config['talon']['db']),
        read_annot = protected(config['talon']['annot'])


use rule talon_abundance as talon_abundance_run with:
    input:
        db = config['talon']['db']
    params:
        genome_ver = config['ref']['fa_ver'],
        annot_ver = config['ref']['gtf_ver'],
        opref = config['talon']['ab'].rsplit('_talon', maxsplit=1)[0]
    output:
        ab = protected(config['talon']['ab'])


use rule talon_filter as talon_filt_run with:
    input:
        db = config['talon']['db']
    params:
        annot_ver = config['ref']['gtf_ver'],
        max_frac_a = config['talon']['max_frac_a'],
        min_count = config['talon']['min_count'],
        min_datasets = config['talon']['min_datasets']
    output:
        pass_list = protected(config['talon']['pass_list'])

use rule talon_filtered_abundance as talon_filt_ab_run with:
    input:
        db = config['talon']['db'],
        pass_list = config['talon']['pass_list']
    params:
        opref = config['talon']['filt_ab'].rsplit('_talon', maxsplit=1)[0],
        genome_ver = config['ref']['fa_ver'],
        annot_ver = config['ref']['gtf_ver']
    output:
        ab = config['talon']['filt_ab']

use rule talon_gtf as talon_gtf_run with:
    input:
        db = config['talon']['db'],
        pass_list = config['talon']['pass_list']
    params:
        opref = config['talon']['gtf'].rsplit('_talon', maxsplit=1)[0],
        genome_ver = config['ref']['fa_ver'],
        annot_ver = config['ref']['gtf_ver']
    output:
        gtf = protected(config['talon']['gtf'])


################################################################################
################################### LAPA #######################################
################################################################################
rule lapa_config:
    input:
        bams = lambda wc:get_cfg_entries(wc, p_df, config['merge']['sort_bam'])
    resources:
        threads = 1,
        mem_gb = 2
    output:
        cfg = protected(config['lapa']['config'])
    run:
        temp = get_cfg_entries(wildcards, p_df, config['merge']['sort_bam'], return_df=True)
        temp = temp[['dataset', 'sample', 'file']].copy(deep=True)

        # argggggh rename these files in the opposite manner because
        # hasan and I have opposite definitions of "sample" and "dataset"
        temp.columns = ['sample', 'dataset', 'path']
        temp.to_csv(output.cfg, sep=',', index=False)

use rule lapa_call_ends as lapa_call_ends_run with:
        input:
            config = config['lapa']['config'],
            fa = rules.map_reads.input.ref_fa,
            gtf = config['ref']['gtf_utr'],
            chrom_sizes = config['ref']['pseudochrom']['chrom_sizes']
        params:
            opref = config['lapa']['ends'].rsplit('/', maxsplit=1)[0]+'/',
            lapa_cmd = lambda wc:get_lapa_settings(wc,
                                    p_df,
                                    config['lapa']['ends'],
                                    'lapa_cmd'),
            lapa_end_temp = lambda wc:get_lapa_settings(wc,
                                p_df,
                                config['lapa']['ends'],
                                'temp_file')
        output:
            ends = protected(config['lapa']['ends'])

use rule lapa_link as lapa_link_run with:
    input:
        annot = config['talon']['annot'],
        tss = expand(config['lapa']['ends'], end_mode='tss', allow_missing=True)[0],
        tes = expand(config['lapa']['ends'], end_mode='tes', allow_missing=True)[0]
    params:
        tss_dir = expand(config['lapa']['ends'], end_mode='tss', allow_missing=True)[0].rsplit('/', maxsplit=1)[0]+'/',
        tes_dir = expand(config['lapa']['ends'], end_mode='tes', allow_missing=True)[0].rsplit('/', maxsplit=1)[0]+'/'
    output:
        links = protected(config['lapa']['links'])

use rule lapa_correct_talon as lapa_correct_talon_run with:
    input:
        gtf = config['talon']['gtf'],
        filt_ab = config['talon']['filt_ab'],
        annot = config['talon']['annot'],
        links = config['lapa']['links']
    output:
        gtf = protected(config['lapa']['corrected']['gtf']),
        filt_ab = protected(config['lapa']['corrected']['filt_ab'])

use rule lapa_filt as lapa_filt_run with:
    input:
        filt_ab = config['lapa']['corrected']['filt_ab'],
        gtf = config['lapa']['corrected']['gtf']
    params:
        t_novs = config['lapa']['filt']['t_novs'],
        g_novs = config['lapa']['filt']['g_novs'],
        filt_spikes = config['lapa']['filt']['remove_spikes']
    output:
        filt_list = protected(config['lapa']['filt']['pass_list'])


use rule lapa_filt_ab as lapa_filt_ab_run with:
    input:
        ab = config['lapa']['corrected']['filt_ab'],
        filt_list = config['lapa']['filt']['pass_list']
    output:
        ab = protected(config['lapa']['filt']['filt_ab'])

use rule lapa_filt_gtf as lapa_filt_gtf_run with:
    input:
        gtf = config['lapa']['corrected']['gtf'],
        filt_list = config['lapa']['filt']['pass_list']
    output:
        gtf = temporary(config['lapa']['filt']['gtf'])

use rule igv_sort_gtf as igv_sort_gtf_lr with:
    input:
        gtf = rules.lapa_filt_gtf_run.output.gtf
    output:
        gtf = protected(config['lapa']['filt']['sort_gtf'])


use rule igv_index_gtf as igv_index_gtf_lr with:
    input:
        gtf = rules.igv_sort_gtf_lr.output.gtf
    output:
        ind = protected(config['lapa']['filt']['ind_gtf'])



################################################################################
################################ Cerberus ######################################
################################################################################
use rule cerb_gtf_to_bed as cerb_get_gtf_ends with:
    input:
        gtf = config['lapa']['filt']['sort_gtf']
    output:
        ends = protected(config['cerberus']['ends'])

    params:
        slack = lambda wc:config['cerberus'][wc.end_mode]['slack'],
        dist = lambda wc:config['cerberus'][wc.end_mode]['dist']

use rule cerb_gtf_to_ics as cerb_get_gtf_ics with:
    input:
        gtf = config['lapa']['filt']['sort_gtf']
    output:
        ics = protected(config['cerberus']['ics'])
